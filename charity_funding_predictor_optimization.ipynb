{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fe9b35",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e615ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for machine learning/neural network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "# for data handling\n",
    "import pandas as pd\n",
    "\n",
    "# general use\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ceb2b",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring in the raw data\n",
    "df0 = pd.read_csv(join(\"resources\", \"charity_data.csv\"))\n",
    "\n",
    "# preview the raw data\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EIN and NAME are unnecessary for the neural net, so we'll drop them from the dataset\n",
    "df1 = df0.drop([\"EIN\", \"NAME\"], axis = 1)\n",
    "\n",
    "# preview the data\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc73a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define unique item threshold\n",
    "unique_item_count = 10\n",
    "\n",
    "# check for columns that require modification\n",
    "modify_columns = []\n",
    "value_count_lists = []\n",
    "for col in df1.nunique().items():\n",
    "    if (col[1] > 10) and (df1[col[0]].dtype == \"object\"):\n",
    "        modify_columns.append(col[0])\n",
    "        value_count_lists.append(df1[col[0]].value_counts())\n",
    "        print(df1[col[0]].value_counts())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify cutoff values for the relevant columns\n",
    "cutoff_values = [200, 1000]\n",
    "\n",
    "# modify the specified columns\n",
    "for i in range(len(modify_columns)):\n",
    "    \n",
    "    # assemble a list of items to be replaced\n",
    "    items_to_replace = []\n",
    "    for item in value_count_lists[i].items():\n",
    "        if item[1] < cutoff_values[i]:\n",
    "            items_to_replace.append(item[0])\n",
    "    \n",
    "    # replace the items of the associated column\n",
    "    for item in items_to_replace:\n",
    "        df1[modify_columns[i]] = df1[modify_columns[i]].replace(item, \"other\")\n",
    "    \n",
    "    # display the modified column\n",
    "    print(df1[modify_columns[i]].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fbaf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace categorical data with numerical data\n",
    "df2 = pd.get_dummies(df1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ffa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features and outputs\n",
    "y = df2[\"IS_SUCCESSFUL\"].values\n",
    "X = df2.drop(\"IS_SUCCESSFUL\", axis = 1).values\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "# create and fit the scaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# scale the features\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039c5b82",
   "metadata": {},
   "source": [
    "### Neural Net Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f05c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the neural net model method\n",
    "def build_model(hp):\n",
    "    \n",
    "    # instantiate the model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # populate activation function options\n",
    "    activation_options = hp.Choice(\"activation\", [\"relu\", \"tanh\", \"sigmoid\"])\n",
    "    \n",
    "    # populate initial layer neurons\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units = hp.Int(\"first_units\", \n",
    "                       min_value = 2, \n",
    "                       max_value = 10, \n",
    "                       step = 2), \n",
    "        activation = activation_options, \n",
    "        input_dim = X_train_scaled.shape[1]))\n",
    "    \n",
    "    # populate hidden layer neurons\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 10)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units = hp.Int(\"units_\" + str(i),\n",
    "                          min_value = 2,\n",
    "                          max_value = 10,\n",
    "                          step = 2),\n",
    "            activation = activation_options))\n",
    "    \n",
    "    # populate output layer neurons\n",
    "    model.add(tf.keras.layers.Dense(units = 1, activation = \"sigmoid\"))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88233865",
   "metadata": {},
   "source": [
    "### Compile, Train, and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f4edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_epochs = 50,\n",
    "    overwrite = True,\n",
    "    hyperband_iterations = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba10a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the tuner\n",
    "tuner.search(X_train_scaled, y_train, epochs = 50, validation_data = (X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the highest performing hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "# preview the hyperparameters\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b283c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model's performance\n",
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_acc = best_model.evaluate(X_test_scaled, y_test, verbose = 2)\n",
    "print(f\"Loss: {model_loss:,.4f}, Accuracy: {model_acc:,.4f}\")\n",
    "\n",
    "# OUTPUT...\n",
    "# 268/268 - 0s - loss: 0.5727 - accuracy: 0.7341 - 375ms/epoch - 1ms/step\n",
    "# Loss: 0.5727, Accuracy: 0.7341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "best_model.save(join(\"output\", \"alphabet_soup_charity_optimized.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601eddc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
